{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.18.0-cp311-cp311-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\hugo trabajo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached protobuf-5.28.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hugo trabajo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hugo trabajo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hugo trabajo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hugo trabajo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading grpcio-1.67.1-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading numpy-2.0.2-cp311-cp311-win_amd64.whl.metadata (59 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading h5py-3.12.1-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading wheel-0.45.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading optree-0.13.1-cp311-cp311-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hugo trabajo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hugo trabajo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hugo trabajo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hugo trabajo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.7.4)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hugo trabajo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.5)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hugo trabajo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.18.0-cp311-cp311-win_amd64.whl (7.5 kB)\n",
      "Downloading tensorflow_intel-2.18.0-cp311-cp311-win_amd64.whl (390.2 MB)\n",
      "   ---------------------------------------- 0.0/390.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.2/390.2 MB 20.9 MB/s eta 0:00:19\n",
      "    --------------------------------------- 9.4/390.2 MB 22.6 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 13.9/390.2 MB 22.4 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 18.4/390.2 MB 21.4 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 23.3/390.2 MB 22.0 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 28.6/390.2 MB 22.4 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 34.6/390.2 MB 23.4 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 36.2/390.2 MB 23.5 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 36.2/390.2 MB 23.5 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 40.4/390.2 MB 19.0 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 48.2/390.2 MB 20.7 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 53.5/390.2 MB 21.6 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 54.5/390.2 MB 20.9 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 54.8/390.2 MB 18.5 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 54.8/390.2 MB 18.5 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 54.8/390.2 MB 18.5 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 54.8/390.2 MB 18.5 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 54.8/390.2 MB 18.5 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 54.8/390.2 MB 18.5 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 54.8/390.2 MB 18.5 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 54.8/390.2 MB 18.5 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 54.8/390.2 MB 18.5 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 54.8/390.2 MB 18.5 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 54.8/390.2 MB 18.5 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 55.3/390.2 MB 10.6 MB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 55.6/390.2 MB 10.2 MB/s eta 0:00:33\n",
      "   ----- ---------------------------------- 56.4/390.2 MB 9.9 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 59.0/390.2 MB 9.9 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 60.6/390.2 MB 9.8 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 61.6/390.2 MB 9.6 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 62.7/390.2 MB 9.5 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 64.7/390.2 MB 9.5 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 66.6/390.2 MB 9.5 MB/s eta 0:00:35\n",
      "   ------- -------------------------------- 69.7/390.2 MB 9.7 MB/s eta 0:00:34\n",
      "   ------- -------------------------------- 71.6/390.2 MB 9.7 MB/s eta 0:00:33\n",
      "   ------- -------------------------------- 73.7/390.2 MB 9.7 MB/s eta 0:00:33\n",
      "   ------- -------------------------------- 77.1/390.2 MB 9.8 MB/s eta 0:00:33\n",
      "   -------- ------------------------------- 80.5/390.2 MB 9.9 MB/s eta 0:00:32\n",
      "   -------- ------------------------------- 81.8/390.2 MB 9.9 MB/s eta 0:00:32\n",
      "   -------- ------------------------------- 81.8/390.2 MB 9.9 MB/s eta 0:00:32\n",
      "   -------- ------------------------------- 81.8/390.2 MB 9.9 MB/s eta 0:00:32\n",
      "   --------- ------------------------------ 90.4/390.2 MB 10.1 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 93.6/390.2 MB 10.2 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 98.0/390.2 MB 10.5 MB/s eta 0:00:28\n",
      "   ---------- ---------------------------- 104.1/390.2 MB 10.8 MB/s eta 0:00:27\n",
      "   ----------- --------------------------- 112.5/390.2 MB 11.4 MB/s eta 0:00:25\n",
      "   ----------- --------------------------- 119.3/390.2 MB 11.9 MB/s eta 0:00:23\n",
      "   ------------ -------------------------- 126.4/390.2 MB 12.3 MB/s eta 0:00:22\n",
      "   ------------- ------------------------- 131.9/390.2 MB 12.7 MB/s eta 0:00:21\n",
      "   ------------- ------------------------- 133.4/390.2 MB 12.6 MB/s eta 0:00:21\n",
      "   ------------- ------------------------- 133.4/390.2 MB 12.6 MB/s eta 0:00:21\n",
      "   ------------- ------------------------- 133.4/390.2 MB 12.6 MB/s eta 0:00:21\n",
      "   ------------- ------------------------- 133.4/390.2 MB 12.6 MB/s eta 0:00:21\n",
      "   ------------- ------------------------- 134.5/390.2 MB 11.8 MB/s eta 0:00:22\n",
      "   ------------- ------------------------- 134.5/390.2 MB 11.8 MB/s eta 0:00:22\n",
      "   ------------- ------------------------- 135.5/390.2 MB 11.5 MB/s eta 0:00:23\n",
      "   ------------- ------------------------- 135.8/390.2 MB 11.1 MB/s eta 0:00:23\n",
      "   ------------- ------------------------- 136.1/390.2 MB 11.1 MB/s eta 0:00:23\n",
      "   ------------- ------------------------- 136.1/390.2 MB 11.1 MB/s eta 0:00:23\n",
      "   ------------- ------------------------- 136.6/390.2 MB 10.7 MB/s eta 0:00:24\n",
      "   ------------- ------------------------- 136.6/390.2 MB 10.7 MB/s eta 0:00:24\n",
      "   ------------- ------------------------- 136.6/390.2 MB 10.7 MB/s eta 0:00:24\n",
      "   ------------- ------------------------- 136.8/390.2 MB 10.1 MB/s eta 0:00:26\n",
      "   ------------- ------------------------- 138.1/390.2 MB 10.2 MB/s eta 0:00:25\n",
      "   ------------- ------------------------- 139.5/390.2 MB 10.0 MB/s eta 0:00:26\n",
      "   -------------- ------------------------ 140.2/390.2 MB 10.0 MB/s eta 0:00:25\n",
      "   -------------- ------------------------ 140.2/390.2 MB 10.0 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 141.6/390.2 MB 9.7 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 143.7/390.2 MB 9.7 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 145.0/390.2 MB 9.7 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 146.3/390.2 MB 9.6 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 146.8/390.2 MB 9.6 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 148.9/390.2 MB 9.5 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 148.9/390.2 MB 9.5 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 148.9/390.2 MB 9.5 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 148.9/390.2 MB 9.5 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 148.9/390.2 MB 9.5 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 148.9/390.2 MB 9.5 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 148.9/390.2 MB 9.5 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 148.9/390.2 MB 9.5 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 148.9/390.2 MB 9.5 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 148.9/390.2 MB 9.5 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 148.9/390.2 MB 9.5 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 148.9/390.2 MB 9.5 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 148.9/390.2 MB 9.5 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 148.9/390.2 MB 9.5 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 148.9/390.2 MB 9.5 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 148.9/390.2 MB 9.5 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 148.9/390.2 MB 9.5 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 148.9/390.2 MB 9.5 MB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 157.0/390.2 MB 8.0 MB/s eta 0:00:30\n",
      "   ---------------- ----------------------- 163.8/390.2 MB 8.3 MB/s eta 0:00:28\n",
      "   ----------------- ---------------------- 171.7/390.2 MB 8.6 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 179.8/390.2 MB 8.9 MB/s eta 0:00:24\n",
      "   ------------------- -------------------- 187.4/390.2 MB 9.2 MB/s eta 0:00:23\n",
      "   ------------------- -------------------- 195.0/390.2 MB 9.4 MB/s eta 0:00:21\n",
      "   -------------------- ------------------- 202.6/390.2 MB 9.7 MB/s eta 0:00:20\n",
      "   -------------------- ------------------ 210.0/390.2 MB 10.0 MB/s eta 0:00:19\n",
      "   --------------------- ----------------- 217.6/390.2 MB 10.2 MB/s eta 0:00:17\n",
      "   ---------------------- ---------------- 225.2/390.2 MB 10.5 MB/s eta 0:00:16\n",
      "   ----------------------- --------------- 232.3/390.2 MB 10.7 MB/s eta 0:00:15\n",
      "   ----------------------- --------------- 239.6/390.2 MB 10.9 MB/s eta 0:00:14\n",
      "   ------------------------ -------------- 247.5/390.2 MB 11.2 MB/s eta 0:00:13\n",
      "   ------------------------- ------------- 252.7/390.2 MB 11.4 MB/s eta 0:00:13\n",
      "   -------------------------- ------------ 262.4/390.2 MB 11.7 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 266.1/390.2 MB 11.6 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 266.1/390.2 MB 11.6 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 266.1/390.2 MB 11.6 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 266.1/390.2 MB 11.6 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 266.6/390.2 MB 11.3 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 266.6/390.2 MB 11.3 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 266.6/390.2 MB 11.3 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 266.6/390.2 MB 11.3 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 267.6/390.2 MB 10.8 MB/s eta 0:00:12\n",
      "   -------------------------- ------------ 267.6/390.2 MB 10.8 MB/s eta 0:00:12\n",
      "   -------------------------- ------------ 267.6/390.2 MB 10.8 MB/s eta 0:00:12\n",
      "   -------------------------- ------------ 268.4/390.2 MB 10.6 MB/s eta 0:00:12\n",
      "   -------------------------- ------------ 268.4/390.2 MB 10.6 MB/s eta 0:00:12\n",
      "   -------------------------- ------------ 268.4/390.2 MB 10.6 MB/s eta 0:00:12\n",
      "   -------------------------- ------------ 269.5/390.2 MB 10.4 MB/s eta 0:00:12\n",
      "   -------------------------- ------------ 269.5/390.2 MB 10.4 MB/s eta 0:00:12\n",
      "   -------------------------- ------------ 269.5/390.2 MB 10.4 MB/s eta 0:00:12\n",
      "   --------------------------- ----------- 270.3/390.2 MB 10.1 MB/s eta 0:00:12\n",
      "   --------------------------- ----------- 270.5/390.2 MB 10.0 MB/s eta 0:00:12\n",
      "   --------------------------- ----------- 270.5/390.2 MB 10.0 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 271.3/390.2 MB 9.9 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 272.6/390.2 MB 9.8 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 272.6/390.2 MB 9.8 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 272.6/390.2 MB 9.8 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 272.6/390.2 MB 9.8 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 272.6/390.2 MB 9.8 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 272.6/390.2 MB 9.8 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 272.6/390.2 MB 9.8 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 272.6/390.2 MB 9.8 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 272.6/390.2 MB 9.8 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 272.6/390.2 MB 9.8 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 272.6/390.2 MB 9.8 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 272.6/390.2 MB 9.8 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 272.6/390.2 MB 9.8 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 272.6/390.2 MB 9.8 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 272.6/390.2 MB 9.8 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 277.9/390.2 MB 8.8 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 289.7/390.2 MB 8.9 MB/s eta 0:00:12\n",
      "   ------------------------------ --------- 295.7/390.2 MB 8.9 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 303.6/390.2 MB 9.0 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 310.9/390.2 MB 9.0 MB/s eta 0:00:09\n",
      "   ------------------------------- ------- 318.2/390.2 MB 10.1 MB/s eta 0:00:08\n",
      "   -------------------------------- ------ 320.3/390.2 MB 10.2 MB/s eta 0:00:07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hugo Trabajo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\Users\\Hugo Trabajo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Hugo Trabajo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Hugo Trabajo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 102, in read\n",
      "    self.__buf.write(data)\n",
      "  File \"C:\\Users\\Hugo Trabajo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tempfile.py\", line 500, in func_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hugo Trabajo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Hugo Trabajo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Hugo Trabajo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Hugo Trabajo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 379, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "                      ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Hugo Trabajo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 179, in resolve\n",
      "    self.factory.preparer.prepare_linked_requirements_more(reqs)\n",
      "  File \"C:\\Users\\Hugo Trabajo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 554, in prepare_linked_requirements_more\n",
      "    self._complete_partial_requirements(\n",
      "  File \"C:\\Users\\Hugo Trabajo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 469, in _complete_partial_requirements\n",
      "    for link, (filepath, _) in batch_download:\n",
      "  File \"C:\\Users\\Hugo Trabajo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_internal\\network\\download.py\", line 184, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"C:\\Users\\Hugo Trabajo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 55, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"C:\\Users\\Hugo Trabajo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 65, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"C:\\Users\\Hugo Trabajo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Hugo Trabajo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 560, in read\n",
      "    with self._error_catcher():\n",
      "  File \"C:\\Users\\Hugo Trabajo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"C:\\Users\\Hugo Trabajo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 455, in _error_catcher\n",
      "    raise ProtocolError(\"Connection broken: %r\" % e, e)\n",
      "pip._vendor.urllib3.exceptions.ProtocolError: (\"Connection broken: OSError(28, 'No space left on device')\", OSError(28, 'No space left on device'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting absl-py (from keras)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\hugo trabajo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras) (2.1.3)\n",
      "Collecting rich (from keras)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting h5py (from keras)\n",
      "  Using cached h5py-3.12.1-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting optree (from keras)\n",
      "  Using cached optree-0.13.1-cp311-cp311-win_amd64.whl.metadata (48 kB)\n",
      "Collecting ml-dtypes (from keras)\n",
      "  Downloading ml_dtypes-0.5.0-cp311-cp311-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\hugo trabajo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\hugo trabajo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optree->keras) (4.12.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hugo trabajo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 19.8 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading h5py-3.12.1-cp311-cp311-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.0/3.0 MB 22.0 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.0-cp311-cp311-win_amd64.whl (211 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.1-cp311-cp311-win_amd64.whl (292 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, optree, ml-dtypes, mdurl, h5py, absl-py, markdown-it-py, rich, keras\n",
      "Successfully installed absl-py-2.1.0 h5py-3.12.1 keras-3.6.0 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.0 namex-0.0.8 optree-0.13.1 rich-13.9.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel Angel\\AppData\\Local\\Temp\\ipykernel_22688\\3096108358.py:3: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5019607843137255"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "255/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13066062"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# Capa entrada\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 300,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 100,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Capa salida\n",
    "model.add(keras.layers.Dense(units = 10,\n",
    "                            activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.layers.reshaping.flatten.Flatten object at 0x0000024513FA6150>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06516822, -0.02765122, -0.04365101, ...,  0.07244295,\n",
       "        -0.07181718, -0.01347364],\n",
       "       [ 0.01760019,  0.03959467,  0.05405323, ...,  0.02997607,\n",
       "         0.0172274 , -0.06462748],\n",
       "       [ 0.03247601,  0.04931118, -0.01084898, ..., -0.03428759,\n",
       "        -0.00917315, -0.0444326 ],\n",
       "       ...,\n",
       "       [ 0.07065867,  0.02230313, -0.00386217, ...,  0.01656929,\n",
       "         0.05591567,  0.03291883],\n",
       "       [-0.03404632, -0.05832689, -0.02117683, ..., -0.00545251,\n",
       "         0.01271288,  0.00571465],\n",
       "       [-0.03921643, -0.00806411, -0.03460707, ...,  0.04452991,\n",
       "         0.04997667, -0.00307342]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300*784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biases)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.SGD(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_4 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266610 (1.02 MB)\n",
      "Trainable params: 266610 (1.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784 * 300 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235500\n"
     ]
    }
   ],
   "source": [
    "# 1º neurona de la 1º hidden layer\n",
    "# y = a + w1*x1 + w2*x2 + .... wn*xn\n",
    "# a es el intercepto llamado bias\n",
    "# wn es cada uno de los pesos que va a ir actualizando con el backpropagation\n",
    "# n es 784\n",
    "# En la 1º hidden layer tenemos 784 pesos por cada neurona, al tener 300, tenemos un total de:\n",
    "print(784*300 + 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 784 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30100"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 100 + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1010"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * 10 + 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 28, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312.5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "40000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 1.4100 - accuracy: 0.6537 - val_loss: 0.7802 - val_accuracy: 0.8310\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.5863 - accuracy: 0.8601 - val_loss: 0.4929 - val_accuracy: 0.8713\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.4306 - accuracy: 0.8865 - val_loss: 0.4139 - val_accuracy: 0.8853\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3718 - accuracy: 0.8979 - val_loss: 0.3710 - val_accuracy: 0.8924\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.3389 - accuracy: 0.9050 - val_loss: 0.3452 - val_accuracy: 0.8984\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.3160 - accuracy: 0.9110 - val_loss: 0.3264 - val_accuracy: 0.9044\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2985 - accuracy: 0.9160 - val_loss: 0.3140 - val_accuracy: 0.9076\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2839 - accuracy: 0.9197 - val_loss: 0.3019 - val_accuracy: 0.9095\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2716 - accuracy: 0.9234 - val_loss: 0.2897 - val_accuracy: 0.9142\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2608 - accuracy: 0.9258 - val_loss: 0.2851 - val_accuracy: 0.9162\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2509 - accuracy: 0.9292 - val_loss: 0.2724 - val_accuracy: 0.9213\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2420 - accuracy: 0.9315 - val_loss: 0.2644 - val_accuracy: 0.9220\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2335 - accuracy: 0.9340 - val_loss: 0.2590 - val_accuracy: 0.9230\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2258 - accuracy: 0.9354 - val_loss: 0.2531 - val_accuracy: 0.9254\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2186 - accuracy: 0.9375 - val_loss: 0.2448 - val_accuracy: 0.9275\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2119 - accuracy: 0.9396 - val_loss: 0.2394 - val_accuracy: 0.9288\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2056 - accuracy: 0.9417 - val_loss: 0.2360 - val_accuracy: 0.9306\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.1995 - accuracy: 0.9432 - val_loss: 0.2289 - val_accuracy: 0.9308\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.1938 - accuracy: 0.9453 - val_loss: 0.2265 - val_accuracy: 0.9337\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.1884 - accuracy: 0.9464 - val_loss: 0.2188 - val_accuracy: 0.9343\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.1831 - accuracy: 0.9477 - val_loss: 0.2151 - val_accuracy: 0.9361\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.1778 - accuracy: 0.9492 - val_loss: 0.2118 - val_accuracy: 0.9365\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.1735 - accuracy: 0.9510 - val_loss: 0.2083 - val_accuracy: 0.9381\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.1689 - accuracy: 0.9520 - val_loss: 0.2029 - val_accuracy: 0.9391\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.1645 - accuracy: 0.9533 - val_loss: 0.2021 - val_accuracy: 0.9393\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.1602 - accuracy: 0.9546 - val_loss: 0.1976 - val_accuracy: 0.9403\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.1562 - accuracy: 0.9553 - val_loss: 0.1928 - val_accuracy: 0.9424\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.1522 - accuracy: 0.9567 - val_loss: 0.1894 - val_accuracy: 0.9428\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.1485 - accuracy: 0.9581 - val_loss: 0.1888 - val_accuracy: 0.9425\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.1450 - accuracy: 0.9589 - val_loss: 0.1851 - val_accuracy: 0.9440\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.1417 - accuracy: 0.9596 - val_loss: 0.1816 - val_accuracy: 0.9446\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.1383 - accuracy: 0.9609 - val_loss: 0.1800 - val_accuracy: 0.9450\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.1352 - accuracy: 0.9617 - val_loss: 0.1756 - val_accuracy: 0.9478\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.1322 - accuracy: 0.9628 - val_loss: 0.1737 - val_accuracy: 0.9477\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.1292 - accuracy: 0.9633 - val_loss: 0.1711 - val_accuracy: 0.9487\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.1262 - accuracy: 0.9644 - val_loss: 0.1695 - val_accuracy: 0.9504\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.1235 - accuracy: 0.9656 - val_loss: 0.1692 - val_accuracy: 0.9485\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.1207 - accuracy: 0.9665 - val_loss: 0.1647 - val_accuracy: 0.9509\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.1181 - accuracy: 0.9673 - val_loss: 0.1628 - val_accuracy: 0.9518\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.1156 - accuracy: 0.9681 - val_loss: 0.1616 - val_accuracy: 0.9513\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.1132 - accuracy: 0.9687 - val_loss: 0.1600 - val_accuracy: 0.9528\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.1108 - accuracy: 0.9689 - val_loss: 0.1568 - val_accuracy: 0.9547\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.1087 - accuracy: 0.9699 - val_loss: 0.1554 - val_accuracy: 0.9538\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1064 - accuracy: 0.9704 - val_loss: 0.1540 - val_accuracy: 0.9541\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1043 - accuracy: 0.9714 - val_loss: 0.1547 - val_accuracy: 0.9534\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.1024 - accuracy: 0.9724 - val_loss: 0.1511 - val_accuracy: 0.9561\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.1004 - accuracy: 0.9729 - val_loss: 0.1491 - val_accuracy: 0.9553\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.0983 - accuracy: 0.9731 - val_loss: 0.1490 - val_accuracy: 0.9562\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0965 - accuracy: 0.9739 - val_loss: 0.1462 - val_accuracy: 0.9563\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0945 - accuracy: 0.9740 - val_loss: 0.1454 - val_accuracy: 0.9564\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0831 - accuracy: 0.9769 - val_loss: 0.1058 - val_accuracy: 0.9709\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0802 - accuracy: 0.9778 - val_loss: 0.1033 - val_accuracy: 0.9708\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0772 - accuracy: 0.9789 - val_loss: 0.1030 - val_accuracy: 0.9726\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0743 - accuracy: 0.9792 - val_loss: 0.0987 - val_accuracy: 0.9729\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0717 - accuracy: 0.9806 - val_loss: 0.0988 - val_accuracy: 0.9732\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.0694 - accuracy: 0.9808 - val_loss: 0.0971 - val_accuracy: 0.9731\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.0666 - accuracy: 0.9822 - val_loss: 0.0962 - val_accuracy: 0.9724\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0646 - accuracy: 0.9826 - val_loss: 0.0955 - val_accuracy: 0.9733\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0625 - accuracy: 0.9830 - val_loss: 0.0922 - val_accuracy: 0.9746\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.0601 - accuracy: 0.9837 - val_loss: 0.0909 - val_accuracy: 0.9741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x227b5f2f910>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 10,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [1.4099534749984741, 0.5862703919410706, 0.43062499165534973, 0.3718400001525879, 0.33887168765068054, 0.3159516453742981, 0.298536479473114, 0.283893883228302, 0.2716282904148102, 0.2607911229133606, 0.2508924901485443, 0.2419794648885727, 0.23352929949760437, 0.22576306760311127, 0.21858525276184082, 0.21192170679569244, 0.2056044489145279, 0.1994848996400833, 0.19376084208488464, 0.1883903592824936, 0.18308137357234955, 0.1778426319360733, 0.1734701693058014, 0.16887831687927246, 0.16449560225009918, 0.16015395522117615, 0.1561783254146576, 0.15220704674720764, 0.14854806661605835, 0.14504361152648926, 0.14172731339931488, 0.1383269727230072, 0.135182723402977, 0.1322307139635086, 0.12916986644268036, 0.12621687352657318, 0.12347214668989182, 0.12070312350988388, 0.1181490570306778, 0.11562322080135345, 0.11317764967679977, 0.1108296737074852, 0.10868114978075027, 0.10636309534311295, 0.10426975041627884, 0.10240141302347183, 0.10036349296569824, 0.09830969572067261, 0.09649959951639175, 0.09445066004991531], 'accuracy': [0.6537250280380249, 0.8600500226020813, 0.8864750266075134, 0.8978750109672546, 0.9050250053405762, 0.9110000133514404, 0.9160000085830688, 0.9197499752044678, 0.9233750104904175, 0.925849974155426, 0.9291750192642212, 0.9314500093460083, 0.9340000152587891, 0.9353749752044678, 0.9375, 0.9395750164985657, 0.9417499899864197, 0.9431750178337097, 0.9452750086784363, 0.946399986743927, 0.947700023651123, 0.9492499828338623, 0.9509750008583069, 0.9520000219345093, 0.9533249735832214, 0.9545999765396118, 0.9553499817848206, 0.9567499756813049, 0.958050012588501, 0.9589499831199646, 0.9596250057220459, 0.9609249830245972, 0.961650013923645, 0.9628000259399414, 0.9632999897003174, 0.9643999934196472, 0.9656000137329102, 0.9664750099182129, 0.96732497215271, 0.9680500030517578, 0.9687250256538391, 0.9689249992370605, 0.9699000120162964, 0.9703999757766724, 0.9714000225067139, 0.9724000096321106, 0.9728500247001648, 0.9730749726295471, 0.9739000201225281, 0.9739999771118164], 'val_loss': [0.780203104019165, 0.49294722080230713, 0.4138803780078888, 0.3710133135318756, 0.34523388743400574, 0.32635951042175293, 0.31399092078208923, 0.3019481301307678, 0.2896977663040161, 0.2850782573223114, 0.27240657806396484, 0.26443663239479065, 0.2590310573577881, 0.2530982494354248, 0.24475201964378357, 0.23939119279384613, 0.2359894961118698, 0.22892309725284576, 0.226479172706604, 0.21884599328041077, 0.21509481966495514, 0.21178148686885834, 0.2083396166563034, 0.20290958881378174, 0.20211248099803925, 0.19757720828056335, 0.19280622899532318, 0.18936146795749664, 0.1887872815132141, 0.1850779503583908, 0.18158815801143646, 0.17996017634868622, 0.17563973367214203, 0.17373637855052948, 0.17106054723262787, 0.16946657001972198, 0.169222891330719, 0.16473311185836792, 0.16276848316192627, 0.16161532700061798, 0.1599564105272293, 0.1568109393119812, 0.15541629493236542, 0.15404027700424194, 0.15474502742290497, 0.15111267566680908, 0.14909985661506653, 0.149046391248703, 0.14622831344604492, 0.14541278779506683], 'val_accuracy': [0.8309999704360962, 0.8712999820709229, 0.8852999806404114, 0.8924000263214111, 0.8984000086784363, 0.9043999910354614, 0.9075999855995178, 0.909500002861023, 0.9142000079154968, 0.9161999821662903, 0.9212999939918518, 0.921999990940094, 0.9229999780654907, 0.9254000186920166, 0.9275000095367432, 0.9287999868392944, 0.9305999875068665, 0.9308000206947327, 0.9337000250816345, 0.9343000054359436, 0.9361000061035156, 0.9365000128746033, 0.9380999803543091, 0.9391000270843506, 0.939300000667572, 0.9402999877929688, 0.9423999786376953, 0.942799985408783, 0.9424999952316284, 0.9440000057220459, 0.944599986076355, 0.9449999928474426, 0.9477999806404114, 0.947700023651123, 0.9487000107765198, 0.9503999948501587, 0.9484999775886536, 0.9509000182151794, 0.9517999887466431, 0.9513000249862671, 0.9527999758720398, 0.9546999931335449, 0.9538000226020813, 0.9541000127792358, 0.9534000158309937, 0.9560999870300293, 0.955299973487854, 0.9562000036239624, 0.9563000202178955, 0.9563999772071838]}\n"
     ]
    }
   ],
   "source": [
    "# print(history.params)\n",
    "# print(history.epoch)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.4099534749984741,\n",
       "  0.5862703919410706,\n",
       "  0.43062499165534973,\n",
       "  0.3718400001525879,\n",
       "  0.33887168765068054,\n",
       "  0.3159516453742981,\n",
       "  0.298536479473114,\n",
       "  0.283893883228302,\n",
       "  0.2716282904148102,\n",
       "  0.2607911229133606,\n",
       "  0.2508924901485443,\n",
       "  0.2419794648885727,\n",
       "  0.23352929949760437,\n",
       "  0.22576306760311127,\n",
       "  0.21858525276184082,\n",
       "  0.21192170679569244,\n",
       "  0.2056044489145279,\n",
       "  0.1994848996400833,\n",
       "  0.19376084208488464,\n",
       "  0.1883903592824936,\n",
       "  0.18308137357234955,\n",
       "  0.1778426319360733,\n",
       "  0.1734701693058014,\n",
       "  0.16887831687927246,\n",
       "  0.16449560225009918,\n",
       "  0.16015395522117615,\n",
       "  0.1561783254146576,\n",
       "  0.15220704674720764,\n",
       "  0.14854806661605835,\n",
       "  0.14504361152648926,\n",
       "  0.14172731339931488,\n",
       "  0.1383269727230072,\n",
       "  0.135182723402977,\n",
       "  0.1322307139635086,\n",
       "  0.12916986644268036,\n",
       "  0.12621687352657318,\n",
       "  0.12347214668989182,\n",
       "  0.12070312350988388,\n",
       "  0.1181490570306778,\n",
       "  0.11562322080135345,\n",
       "  0.11317764967679977,\n",
       "  0.1108296737074852,\n",
       "  0.10868114978075027,\n",
       "  0.10636309534311295,\n",
       "  0.10426975041627884,\n",
       "  0.10240141302347183,\n",
       "  0.10036349296569824,\n",
       "  0.09830969572067261,\n",
       "  0.09649959951639175,\n",
       "  0.09445066004991531],\n",
       " 'accuracy': [0.6537250280380249,\n",
       "  0.8600500226020813,\n",
       "  0.8864750266075134,\n",
       "  0.8978750109672546,\n",
       "  0.9050250053405762,\n",
       "  0.9110000133514404,\n",
       "  0.9160000085830688,\n",
       "  0.9197499752044678,\n",
       "  0.9233750104904175,\n",
       "  0.925849974155426,\n",
       "  0.9291750192642212,\n",
       "  0.9314500093460083,\n",
       "  0.9340000152587891,\n",
       "  0.9353749752044678,\n",
       "  0.9375,\n",
       "  0.9395750164985657,\n",
       "  0.9417499899864197,\n",
       "  0.9431750178337097,\n",
       "  0.9452750086784363,\n",
       "  0.946399986743927,\n",
       "  0.947700023651123,\n",
       "  0.9492499828338623,\n",
       "  0.9509750008583069,\n",
       "  0.9520000219345093,\n",
       "  0.9533249735832214,\n",
       "  0.9545999765396118,\n",
       "  0.9553499817848206,\n",
       "  0.9567499756813049,\n",
       "  0.958050012588501,\n",
       "  0.9589499831199646,\n",
       "  0.9596250057220459,\n",
       "  0.9609249830245972,\n",
       "  0.961650013923645,\n",
       "  0.9628000259399414,\n",
       "  0.9632999897003174,\n",
       "  0.9643999934196472,\n",
       "  0.9656000137329102,\n",
       "  0.9664750099182129,\n",
       "  0.96732497215271,\n",
       "  0.9680500030517578,\n",
       "  0.9687250256538391,\n",
       "  0.9689249992370605,\n",
       "  0.9699000120162964,\n",
       "  0.9703999757766724,\n",
       "  0.9714000225067139,\n",
       "  0.9724000096321106,\n",
       "  0.9728500247001648,\n",
       "  0.9730749726295471,\n",
       "  0.9739000201225281,\n",
       "  0.9739999771118164],\n",
       " 'val_loss': [0.780203104019165,\n",
       "  0.49294722080230713,\n",
       "  0.4138803780078888,\n",
       "  0.3710133135318756,\n",
       "  0.34523388743400574,\n",
       "  0.32635951042175293,\n",
       "  0.31399092078208923,\n",
       "  0.3019481301307678,\n",
       "  0.2896977663040161,\n",
       "  0.2850782573223114,\n",
       "  0.27240657806396484,\n",
       "  0.26443663239479065,\n",
       "  0.2590310573577881,\n",
       "  0.2530982494354248,\n",
       "  0.24475201964378357,\n",
       "  0.23939119279384613,\n",
       "  0.2359894961118698,\n",
       "  0.22892309725284576,\n",
       "  0.226479172706604,\n",
       "  0.21884599328041077,\n",
       "  0.21509481966495514,\n",
       "  0.21178148686885834,\n",
       "  0.2083396166563034,\n",
       "  0.20290958881378174,\n",
       "  0.20211248099803925,\n",
       "  0.19757720828056335,\n",
       "  0.19280622899532318,\n",
       "  0.18936146795749664,\n",
       "  0.1887872815132141,\n",
       "  0.1850779503583908,\n",
       "  0.18158815801143646,\n",
       "  0.17996017634868622,\n",
       "  0.17563973367214203,\n",
       "  0.17373637855052948,\n",
       "  0.17106054723262787,\n",
       "  0.16946657001972198,\n",
       "  0.169222891330719,\n",
       "  0.16473311185836792,\n",
       "  0.16276848316192627,\n",
       "  0.16161532700061798,\n",
       "  0.1599564105272293,\n",
       "  0.1568109393119812,\n",
       "  0.15541629493236542,\n",
       "  0.15404027700424194,\n",
       "  0.15474502742290497,\n",
       "  0.15111267566680908,\n",
       "  0.14909985661506653,\n",
       "  0.149046391248703,\n",
       "  0.14622831344604492,\n",
       "  0.14541278779506683],\n",
       " 'val_accuracy': [0.8309999704360962,\n",
       "  0.8712999820709229,\n",
       "  0.8852999806404114,\n",
       "  0.8924000263214111,\n",
       "  0.8984000086784363,\n",
       "  0.9043999910354614,\n",
       "  0.9075999855995178,\n",
       "  0.909500002861023,\n",
       "  0.9142000079154968,\n",
       "  0.9161999821662903,\n",
       "  0.9212999939918518,\n",
       "  0.921999990940094,\n",
       "  0.9229999780654907,\n",
       "  0.9254000186920166,\n",
       "  0.9275000095367432,\n",
       "  0.9287999868392944,\n",
       "  0.9305999875068665,\n",
       "  0.9308000206947327,\n",
       "  0.9337000250816345,\n",
       "  0.9343000054359436,\n",
       "  0.9361000061035156,\n",
       "  0.9365000128746033,\n",
       "  0.9380999803543091,\n",
       "  0.9391000270843506,\n",
       "  0.939300000667572,\n",
       "  0.9402999877929688,\n",
       "  0.9423999786376953,\n",
       "  0.942799985408783,\n",
       "  0.9424999952316284,\n",
       "  0.9440000057220459,\n",
       "  0.944599986076355,\n",
       "  0.9449999928474426,\n",
       "  0.9477999806404114,\n",
       "  0.947700023651123,\n",
       "  0.9487000107765198,\n",
       "  0.9503999948501587,\n",
       "  0.9484999775886536,\n",
       "  0.9509000182151794,\n",
       "  0.9517999887466431,\n",
       "  0.9513000249862671,\n",
       "  0.9527999758720398,\n",
       "  0.9546999931335449,\n",
       "  0.9538000226020813,\n",
       "  0.9541000127792358,\n",
       "  0.9534000158309937,\n",
       "  0.9560999870300293,\n",
       "  0.955299973487854,\n",
       "  0.9562000036239624,\n",
       "  0.9563000202178955,\n",
       "  0.9563999772071838]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.409953</td>\n",
       "      <td>0.653725</td>\n",
       "      <td>0.780203</td>\n",
       "      <td>0.8310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.586270</td>\n",
       "      <td>0.860050</td>\n",
       "      <td>0.492947</td>\n",
       "      <td>0.8713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.430625</td>\n",
       "      <td>0.886475</td>\n",
       "      <td>0.413880</td>\n",
       "      <td>0.8853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.371840</td>\n",
       "      <td>0.897875</td>\n",
       "      <td>0.371013</td>\n",
       "      <td>0.8924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.338872</td>\n",
       "      <td>0.905025</td>\n",
       "      <td>0.345234</td>\n",
       "      <td>0.8984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.315952</td>\n",
       "      <td>0.911000</td>\n",
       "      <td>0.326360</td>\n",
       "      <td>0.9044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.298536</td>\n",
       "      <td>0.916000</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>0.9076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.283894</td>\n",
       "      <td>0.919750</td>\n",
       "      <td>0.301948</td>\n",
       "      <td>0.9095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.271628</td>\n",
       "      <td>0.923375</td>\n",
       "      <td>0.289698</td>\n",
       "      <td>0.9142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.260791</td>\n",
       "      <td>0.925850</td>\n",
       "      <td>0.285078</td>\n",
       "      <td>0.9162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.250892</td>\n",
       "      <td>0.929175</td>\n",
       "      <td>0.272407</td>\n",
       "      <td>0.9213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.241979</td>\n",
       "      <td>0.931450</td>\n",
       "      <td>0.264437</td>\n",
       "      <td>0.9220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.233529</td>\n",
       "      <td>0.934000</td>\n",
       "      <td>0.259031</td>\n",
       "      <td>0.9230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.225763</td>\n",
       "      <td>0.935375</td>\n",
       "      <td>0.253098</td>\n",
       "      <td>0.9254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.218585</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.244752</td>\n",
       "      <td>0.9275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.211922</td>\n",
       "      <td>0.939575</td>\n",
       "      <td>0.239391</td>\n",
       "      <td>0.9288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.205604</td>\n",
       "      <td>0.941750</td>\n",
       "      <td>0.235989</td>\n",
       "      <td>0.9306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.199485</td>\n",
       "      <td>0.943175</td>\n",
       "      <td>0.228923</td>\n",
       "      <td>0.9308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.193761</td>\n",
       "      <td>0.945275</td>\n",
       "      <td>0.226479</td>\n",
       "      <td>0.9337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.188390</td>\n",
       "      <td>0.946400</td>\n",
       "      <td>0.218846</td>\n",
       "      <td>0.9343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.183081</td>\n",
       "      <td>0.947700</td>\n",
       "      <td>0.215095</td>\n",
       "      <td>0.9361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.177843</td>\n",
       "      <td>0.949250</td>\n",
       "      <td>0.211781</td>\n",
       "      <td>0.9365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.173470</td>\n",
       "      <td>0.950975</td>\n",
       "      <td>0.208340</td>\n",
       "      <td>0.9381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.168878</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.202910</td>\n",
       "      <td>0.9391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.164496</td>\n",
       "      <td>0.953325</td>\n",
       "      <td>0.202112</td>\n",
       "      <td>0.9393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.160154</td>\n",
       "      <td>0.954600</td>\n",
       "      <td>0.197577</td>\n",
       "      <td>0.9403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.156178</td>\n",
       "      <td>0.955350</td>\n",
       "      <td>0.192806</td>\n",
       "      <td>0.9424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.152207</td>\n",
       "      <td>0.956750</td>\n",
       "      <td>0.189361</td>\n",
       "      <td>0.9428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.148548</td>\n",
       "      <td>0.958050</td>\n",
       "      <td>0.188787</td>\n",
       "      <td>0.9425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.145044</td>\n",
       "      <td>0.958950</td>\n",
       "      <td>0.185078</td>\n",
       "      <td>0.9440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.141727</td>\n",
       "      <td>0.959625</td>\n",
       "      <td>0.181588</td>\n",
       "      <td>0.9446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.138327</td>\n",
       "      <td>0.960925</td>\n",
       "      <td>0.179960</td>\n",
       "      <td>0.9450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.135183</td>\n",
       "      <td>0.961650</td>\n",
       "      <td>0.175640</td>\n",
       "      <td>0.9478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.132231</td>\n",
       "      <td>0.962800</td>\n",
       "      <td>0.173736</td>\n",
       "      <td>0.9477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.129170</td>\n",
       "      <td>0.963300</td>\n",
       "      <td>0.171061</td>\n",
       "      <td>0.9487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.126217</td>\n",
       "      <td>0.964400</td>\n",
       "      <td>0.169467</td>\n",
       "      <td>0.9504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.123472</td>\n",
       "      <td>0.965600</td>\n",
       "      <td>0.169223</td>\n",
       "      <td>0.9485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.120703</td>\n",
       "      <td>0.966475</td>\n",
       "      <td>0.164733</td>\n",
       "      <td>0.9509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.118149</td>\n",
       "      <td>0.967325</td>\n",
       "      <td>0.162768</td>\n",
       "      <td>0.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.115623</td>\n",
       "      <td>0.968050</td>\n",
       "      <td>0.161615</td>\n",
       "      <td>0.9513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.113178</td>\n",
       "      <td>0.968725</td>\n",
       "      <td>0.159956</td>\n",
       "      <td>0.9528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.110830</td>\n",
       "      <td>0.968925</td>\n",
       "      <td>0.156811</td>\n",
       "      <td>0.9547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.108681</td>\n",
       "      <td>0.969900</td>\n",
       "      <td>0.155416</td>\n",
       "      <td>0.9538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.106363</td>\n",
       "      <td>0.970400</td>\n",
       "      <td>0.154040</td>\n",
       "      <td>0.9541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.104270</td>\n",
       "      <td>0.971400</td>\n",
       "      <td>0.154745</td>\n",
       "      <td>0.9534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.102401</td>\n",
       "      <td>0.972400</td>\n",
       "      <td>0.151113</td>\n",
       "      <td>0.9561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.100363</td>\n",
       "      <td>0.972850</td>\n",
       "      <td>0.149100</td>\n",
       "      <td>0.9553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.098310</td>\n",
       "      <td>0.973075</td>\n",
       "      <td>0.149046</td>\n",
       "      <td>0.9562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.096500</td>\n",
       "      <td>0.973900</td>\n",
       "      <td>0.146228</td>\n",
       "      <td>0.9563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.094451</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>0.145413</td>\n",
       "      <td>0.9564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   1.409953  0.653725  0.780203        0.8310\n",
       "1   0.586270  0.860050  0.492947        0.8713\n",
       "2   0.430625  0.886475  0.413880        0.8853\n",
       "3   0.371840  0.897875  0.371013        0.8924\n",
       "4   0.338872  0.905025  0.345234        0.8984\n",
       "5   0.315952  0.911000  0.326360        0.9044\n",
       "6   0.298536  0.916000  0.313991        0.9076\n",
       "7   0.283894  0.919750  0.301948        0.9095\n",
       "8   0.271628  0.923375  0.289698        0.9142\n",
       "9   0.260791  0.925850  0.285078        0.9162\n",
       "10  0.250892  0.929175  0.272407        0.9213\n",
       "11  0.241979  0.931450  0.264437        0.9220\n",
       "12  0.233529  0.934000  0.259031        0.9230\n",
       "13  0.225763  0.935375  0.253098        0.9254\n",
       "14  0.218585  0.937500  0.244752        0.9275\n",
       "15  0.211922  0.939575  0.239391        0.9288\n",
       "16  0.205604  0.941750  0.235989        0.9306\n",
       "17  0.199485  0.943175  0.228923        0.9308\n",
       "18  0.193761  0.945275  0.226479        0.9337\n",
       "19  0.188390  0.946400  0.218846        0.9343\n",
       "20  0.183081  0.947700  0.215095        0.9361\n",
       "21  0.177843  0.949250  0.211781        0.9365\n",
       "22  0.173470  0.950975  0.208340        0.9381\n",
       "23  0.168878  0.952000  0.202910        0.9391\n",
       "24  0.164496  0.953325  0.202112        0.9393\n",
       "25  0.160154  0.954600  0.197577        0.9403\n",
       "26  0.156178  0.955350  0.192806        0.9424\n",
       "27  0.152207  0.956750  0.189361        0.9428\n",
       "28  0.148548  0.958050  0.188787        0.9425\n",
       "29  0.145044  0.958950  0.185078        0.9440\n",
       "30  0.141727  0.959625  0.181588        0.9446\n",
       "31  0.138327  0.960925  0.179960        0.9450\n",
       "32  0.135183  0.961650  0.175640        0.9478\n",
       "33  0.132231  0.962800  0.173736        0.9477\n",
       "34  0.129170  0.963300  0.171061        0.9487\n",
       "35  0.126217  0.964400  0.169467        0.9504\n",
       "36  0.123472  0.965600  0.169223        0.9485\n",
       "37  0.120703  0.966475  0.164733        0.9509\n",
       "38  0.118149  0.967325  0.162768        0.9518\n",
       "39  0.115623  0.968050  0.161615        0.9513\n",
       "40  0.113178  0.968725  0.159956        0.9528\n",
       "41  0.110830  0.968925  0.156811        0.9547\n",
       "42  0.108681  0.969900  0.155416        0.9538\n",
       "43  0.106363  0.970400  0.154040        0.9541\n",
       "44  0.104270  0.971400  0.154745        0.9534\n",
       "45  0.102401  0.972400  0.151113        0.9561\n",
       "46  0.100363  0.972850  0.149100        0.9553\n",
       "47  0.098310  0.973075  0.149046        0.9562\n",
       "48  0.096500  0.973900  0.146228        0.9563\n",
       "49  0.094451  0.974000  0.145413        0.9564"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1185 - accuracy: 0.9654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11849593371152878, 0.965399980545044]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel Angel\\AppData\\Local\\Temp\\ipykernel_22688\\1468152043.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "         0.23529412, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "         0.99607843, 0.94509804, 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.6666667 , 0.20392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2627451 , 0.44705883, 0.28235295, 0.44705883,\n",
       "         0.6392157 , 0.8901961 , 0.99607843, 0.88235295, 0.99607843,\n",
       "         0.99607843, 0.99607843, 0.98039216, 0.8980392 , 0.99607843,\n",
       "         0.99607843, 0.54901963, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "         0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "         0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "         0.81960785, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08627451, 0.9137255 , 1.        ,\n",
       "         0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5058824 , 0.99607843, 0.93333334,\n",
       "         0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23137255, 0.9764706 , 0.99607843, 0.24313726,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.8039216 , 0.972549  , 0.22745098, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49411765, 0.99607843, 0.7137255 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "         0.9843137 , 0.9411765 , 0.22352941, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07450981, 0.8666667 ,\n",
       "         0.99607843, 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "         0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "         0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12156863, 0.8784314 , 0.99607843, 0.4509804 ,\n",
       "         0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23921569, 0.9490196 , 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.8117647 , 0.07058824, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 331ms/step\n",
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.8400918e-05, 8.0030055e-08, 8.6574559e-04, 5.9689097e-03,\n",
       "        3.2303367e-07, 2.9543975e-05, 2.8509031e-09, 9.9297005e-01,\n",
       "        1.3050954e-05, 1.0394610e-04]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1])\n",
    "print(predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel Angel\\AppData\\Local\\Temp\\ipykernel_7740\\4029188365.py:1: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_test[1].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[1].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 964,    0,    1,    2,    0,    4,    6,    2,    1,    0],\n",
       "       [   0, 1118,    2,    2,    0,    1,    3,    2,    7,    0],\n",
       "       [   4,    3,  994,    5,    5,    1,    4,   10,    6,    0],\n",
       "       [   1,    0,    6,  975,    0,    9,    0,   10,    7,    2],\n",
       "       [   1,    0,    6,    0,  954,    0,    3,    3,    2,   13],\n",
       "       [   7,    1,    0,   10,    1,  854,    9,    1,    6,    3],\n",
       "       [   7,    3,    3,    1,    5,    7,  926,    2,    4,    0],\n",
       "       [   1,   10,    9,    4,    1,    1,    0,  997,    0,    5],\n",
       "       [   4,    0,    4,   12,    3,    6,    7,    8,  926,    4],\n",
       "       [   5,    5,    3,   11,   19,    3,    1,   12,    4,  946]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "confusion_matrix(y_test, model.predict(X_test).argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.98       980\n",
      "         1.0       0.98      0.99      0.98      1135\n",
      "         2.0       0.97      0.96      0.97      1032\n",
      "         3.0       0.95      0.97      0.96      1010\n",
      "         4.0       0.97      0.97      0.97       982\n",
      "         5.0       0.96      0.96      0.96       892\n",
      "         6.0       0.97      0.97      0.97       958\n",
      "         7.0       0.95      0.97      0.96      1028\n",
      "         8.0       0.96      0.95      0.96       974\n",
      "         9.0       0.97      0.94      0.95      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict(X_test).argmax(axis=1)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362.8125"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11610/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7922 - val_loss: 0.5356\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.5573 - val_loss: 0.4969\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.6598 - val_loss: 0.5584\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.0699 - val_loss: 0.4970\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.5034 - val_loss: 0.4566\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4692 - val_loss: 0.4372\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4523 - val_loss: 0.4243\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4348 - val_loss: 0.4204\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4181 - val_loss: 0.3997\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4068 - val_loss: 0.3998\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4131 - val_loss: 0.3924\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4011 - val_loss: 0.3909\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3978 - val_loss: 0.3871\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3925 - val_loss: 0.3789\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3896 - val_loss: 0.3750\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3827 - val_loss: 0.3685\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3787 - val_loss: 0.3666\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3760 - val_loss: 0.3677\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3797 - val_loss: 0.3738\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3809 - val_loss: 0.3638\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu',\n",
    "                      input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\",\n",
    "             optimizer = \"sgd\")\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs = 20,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*30 + 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 30)                270       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301 (1.18 KB)\n",
      "Trainable params: 301 (1.18 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.3690\n",
      "0.3689943850040436\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 185ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9587051],\n",
       "       [1.426266 ],\n",
       "       [1.7809234],\n",
       "       [1.7333926],\n",
       "       [1.456934 ]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.keras\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3863\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3670\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3617\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3589\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3609\n",
      "Epoch 6/30\n",
      "140/363 [==========>...................] - ETA: 0s - loss: 0.3292"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m checkpoint_cb \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback_model.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                   \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.keras\")\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=30,\n",
    "                   callbacks = [checkpoint_cb])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3101 - val_loss: 0.3038\n",
      "Epoch 2/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3099 - val_loss: 0.3063\n",
      "Epoch 3/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3092 - val_loss: 0.3139\n",
      "Epoch 4/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3085 - val_loss: 0.3127\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3)\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=50,\n",
    "                   validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [early_stopping_cb, checkpoint_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
